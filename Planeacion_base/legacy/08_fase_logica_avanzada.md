# 08. Fase de L√≥gica Avanzada: System Prompts

**Objetivo:** Permitir la creaci√≥n y evaluaci√≥n efectiva de **System Prompts**, diferenci√°ndolos de los prompts normales. Un System Prompt no puede evaluarse solo con verlo; requiere un "User Input" de prueba para ver c√≥mo reacciona el modelo.

## üß† Estrategia T√©cnica
Esta fase implementa la l√≥gica condicional en el motor de ejecuci√≥n (`llm_engine.py`) y en la interfaz de usuario (`ArenaView`), permitiendo inyectar variables de prueba en tiempo real.

---

## üõ†Ô∏è Tareas T√©cnicas Detalladas

### 8.1 Backend: L√≥gica de Ejecuci√≥n Condicional
El motor debe saber distinguir si est√° ejecutando un Prompt Normal (Usuario) o un System Prompt.

- [ ] **Actualizaci√≥n de `llm_engine.py`:**
    - Revisar la funci√≥n `run_prompt_variant`.
    - **L√≥gica System Prompt:**
        - Si `prompt_type == "system"`:
            - Validar que existe `input_data["user_test_input"]`.
            - Construir mensaje: `[{"role": "system", "content": variant}, {"role": "user", "content": test_input}]`.
    - **L√≥gica Normal Prompt:**
        - Si `prompt_type == "normal"`:
            - Construir mensaje: `[{"role": "user", "content": variant}]` (o template renderizado).

### 8.2 Frontend: UI de Testing en Arena
La interfaz debe cambiar cuando el usuario est√° creando un System Prompt.

- [ ] **Input de Prueba Global:**
    - Agregar un campo de texto `Test Input` en la parte superior de la Arena.
    - Este input es **com√∫n** para las 3 variantes.
- [ ] **Bot√≥n "Test Run":**
    - Acci√≥n: Enviar el `Test Input` al backend (`/arena/execute`).
    - Estado: Mostrar loading en las 3 columnas de variantes simult√°neamente.
- [ ] **Visualizaci√≥n de Resultados:**
    - Mostrar la respuesta del modelo (Output) debajo de cada variante.
    - Permitir re-ejecutar con diferente input de prueba sin regenerar las variantes.

### 8.3 Backend: Validaci√≥n de Inputs
- [ ] **Endpoint `/arena/execute`:**
    - Validar que si `prompt_type="system"`, el campo `input_data.user_test_input` no est√© vac√≠o.
    - Retornar error 400 claro si falta el input de prueba.

---

## ‚ùì Preguntas Clave para la Implementaci√≥n
1.  **Variables en el System Prompt:** Si el system prompt tiene variables (ej: `{{ role }}`), ¬ød√≥nde las define el usuario?
    *   *Respuesta:* Por ahora asumimos system prompts est√°ticos o que el agente generador ya rellen√≥ las variables. Si queremos variables din√°micas, necesitamos un paso previo de "Rellenar Variables".
    *   *Decisi√≥n:* Para esta fase, asumir que las variantes generadas ya tienen el contenido final del system prompt.
2.  **Modelo de Ejecuci√≥n:** ¬øQu√© modelo se usa para probar el system prompt?
    *   *Decisi√≥n:* El mismo que el usuario configur√≥ en Settings (ej: GPT-4).

---

## ‚úÖ Buenas Pr√°cticas a Seguir
-   **Claridad Visual:** Diferenciar claramente qu√© es el "Prompt" (instrucci√≥n al modelo) y qu√© es el "Output" (respuesta del modelo ante el input de prueba).
-   **Costos:** Advertir al usuario (quiz√°s un tooltip) que probar 3 variantes con un input largo consume tokens x3.
